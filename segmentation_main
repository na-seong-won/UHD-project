import os.path
import tensorflow as tf
import helper
import warnings
from distutils.version import LooseVersion
import project_test as test

#Check for a GPU

if not tf.test.gpu_device_name():
    warnings.warn('No GPU found. please use a GPU to train your neural network')
else:
    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))


def load_vgg(sess, vgg_path):
    """
    Load Pretrained VGG Model into Tensorflow
    :param sees: Tensorflow Session
    :param vgg_path: vgg_path to vgg folder, containing "variables/"and"saved_model.pb"
    :return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3_out, layer4_out, layer7_out)
    """

    #load the model and weights
    model = tf.saved_model.loader.load(sess, ['vgg16'], vgg_path)

    #Get Tensors to be returned from graph
    graph = tf.get_default_graph()
    image_input = graph.get_tensor_by_name('image_input:0')
    keep_prob= graph.get_tensor_by_name('keep_prob:0')
    layer3 = graph.get_tensor_by_name('layer3_out:0')
    layer4 = graph.get_tensor_by_name('layer4_out:0')
    layer7 = graph.get_tensor_by_name('layer7_out:0')

    return image_input, keep_prob, layer3, layer4, layer7

